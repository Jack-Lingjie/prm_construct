{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "  \n",
    "def check_logs(directory, target_string):  \n",
    "    # 遍历目录中的所有文件  \n",
    "    for root, dirs, files in os.walk(directory):  \n",
    "        for file in files:  \n",
    "            # 只处理.log文件  \n",
    "            if file.endswith('.log'):  \n",
    "                file_path = os.path.join(root, file)  \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:  \n",
    "                    content = f.read()  \n",
    "                    # 检查文件中是否包含目标字符串  \n",
    "                    if target_string not in content:  \n",
    "                        print(f\"{file_path} 不包含 {target_string}\")  \n",
    "  \n",
    "# 指定目录和目标字符串  \n",
    "log_directory = '/mnt/lingjiejiang/textual_aesthetics/prm/data/logs'  \n",
    "target = 'Processing task 250/250'  \n",
    "  \n",
    "# 检查日志文件  \n",
    "check_logs(log_directory, target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并完成，共合并了 48 个文件，结果存储在 <_io.TextIOWrapper name='/mnt/lingjiejiang/textual_aesthetics/prm/data/data/merge_results/merged_results.jsonl' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import json  \n",
    "  \n",
    "# 指定源目录和目标文件路径  \n",
    "source_dir = \"/mnt/lingjiejiang/textual_aesthetics/prm/data/data/prm_results/\"  \n",
    "output_file = \"/mnt/lingjiejiang/textual_aesthetics/prm/data/data/merge_results/merged_results.jsonl\"  \n",
    "  \n",
    "# 获取源目录下所有文件的列表  \n",
    "file_list = [f for f in os.listdir(source_dir) if f.endswith('.json')]  \n",
    "  \n",
    "# 初始化一个空列表，用于存储所有文件的数据  \n",
    "all_data = []  \n",
    "  \n",
    "# 逐个读取文件并将数据追加到all_data列表中  \n",
    "for file_name in file_list:  \n",
    "    file_path = os.path.join(source_dir, file_name)  \n",
    "    with open(file_path, 'r') as file:  \n",
    "        for line in file:  \n",
    "            all_data.append(json.loads(line))  \n",
    "  \n",
    "# 将合并后的数据写入目标文件  \n",
    "with open(output_file, 'w') as output_file:  \n",
    "    for item in all_data:  \n",
    "        output_file.write(json.dumps(item) + '\\n')  \n",
    "  \n",
    "print(f\"合并完成，共合并了 {len(file_list)} 个文件，结果存储在 {output_file}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import re\n",
    "class Node:  \n",
    "    def __init__(self, qid, idx, x, y, step, parent=None, next_nodes=None, gt_answer=None, category=None):  \n",
    "        self.qid = qid  \n",
    "        self.idx = idx  \n",
    "        self.x = x  \n",
    "        self.y = y  \n",
    "        self.step = step  \n",
    "        self.parent = parent  \n",
    "        self.next_nodes = next_nodes if next_nodes is not None else []  \n",
    "        self.gt_answer = gt_answer  \n",
    "        self.pred_acc = self.get_acc()  \n",
    "        self.is_leaf = False  \n",
    "        self.is_right = False  \n",
    "        self.label_he = 0  \n",
    "        self.label_se = 0  \n",
    "        self.he_list = []  \n",
    "        self.se_list = []  \n",
    "        self.category = category  \n",
    "  \n",
    "    def get_acc(self):  \n",
    "        pred = extract_answer(self.y)  \n",
    "        self.pred = pred  \n",
    "        if pred == self.gt_answer:  \n",
    "            return True  \n",
    "        else:  \n",
    "            return False  \n",
    "  \n",
    "    def get_info(self):  \n",
    "        return {  \n",
    "            'qid': self.qid,  \n",
    "            'idx': self.idx,  \n",
    "            'x': self.x,  \n",
    "            'y': self.y,  \n",
    "            'step': self.step,  \n",
    "            'parent': self.parent,  \n",
    "            'next_nodes': self.next_nodes,  \n",
    "            'pred_acc': self.pred_acc,  \n",
    "            \"label_he\": self.label_he,  \n",
    "            \"label_se\": self.label_se,  \n",
    "            \"gt_answer\": self.gt_answer,  \n",
    "            \"pred_acc\": self.pred_acc,  \n",
    "            \"pred\": self.pred,  \n",
    "            \"he_list\": self.he_list,  \n",
    "            \"se_list\": self.se_list,  \n",
    "            \"category\": self.category  \n",
    "        }  \n",
    "  \n",
    "def extract_answer(text):  \n",
    "    pattern = r\"answer is[:\\s]*\\(?(?P<answer>[A-J])\\)?\"  \n",
    "    match = re.search(pattern, text, re.IGNORECASE)  \n",
    "    if match:  \n",
    "        return match.group(\"answer\")  \n",
    "    else:  \n",
    "        return extract_again(text)  \n",
    "  \n",
    "def extract_again(text):  \n",
    "    pattern = r'.*[aA]nswer[:\\s]*([A-J])'  \n",
    "    match = re.search(pattern, text)  \n",
    "    if match:  \n",
    "        return match.group(1)  \n",
    "    else:  \n",
    "        return extract_final(text)  \n",
    "  \n",
    "def extract_final(text):  \n",
    "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"  \n",
    "    match = re.search(pattern, text, re.DOTALL)  \n",
    "    if match:  \n",
    "        return match.group(0)  \n",
    "    else:  \n",
    "        return None  \n",
    "  \n",
    "def load_nodes_from_jsonl(file_path):  \n",
    "    all_nodes = []  \n",
    "    with open(file_path, 'r') as f:  \n",
    "        for line in f:  \n",
    "            if line.strip():  # 跳过空行  \n",
    "                try:  \n",
    "                    node_info = json.loads(line.strip())  \n",
    "                    all_nodes.append(node_info)  \n",
    "                except json.JSONDecodeError as e:  \n",
    "                    print(f\"Error decoding JSON: {e}\")  \n",
    "    return all_nodes  \n",
    "  \n",
    "def get_leaf_nodes_at_step(all_nodes, step):  \n",
    "    leaf_nodes = []  \n",
    "    for node in all_nodes:  \n",
    "        if node.step == step:  \n",
    "            leaf_info = {  \n",
    "                'qid': node.qid,  \n",
    "                'idx': node.idx,  \n",
    "                \"category\": node.category,  \n",
    "                'step': node.step,  \n",
    "                'question': node.x,  \n",
    "                'answer': node.y,  \n",
    "                'hard_estimation': node.he_list,  \n",
    "                'soft_estimation': node.se_list,  \n",
    "                \"gt_answer\": node.gt_answer,  \n",
    "                \"pred\": node.pred  \n",
    "            }  \n",
    "            leaf_nodes.append(leaf_info)  \n",
    "    return leaf_nodes  \n",
    "  \n",
    "def write_leaf_nodes_to_file(leaf_nodes, output_file):  \n",
    "    with open(output_file, 'w') as f:  \n",
    "        for leaf in leaf_nodes:  \n",
    "            f.write(json.dumps(leaf) + '\\n')  \n",
    "  \n",
    "# 示例使用  \n",
    "input_file = '/mnt/lingjiejiang/textual_aesthetics/prm/data/data/prm_tree_path/Meta-Llama-3.1-8B-Instruct_0.8_Meta-Llama-3.1-8B-Instruct3_match1_greedy1_start0_end250.json'  # 替换为你的输入文件路径  \n",
    "output_file = 'data/decode_step/path_to_output_file.json'  # 替换为你的输出文件路径  \n",
    "step = 3  # 替换为你想要获取的层级  \n",
    "  \n",
    "# 加载节点  \n",
    "all_nodes = load_nodes_from_jsonl(input_file)  \n",
    "  \n",
    "# 获取指定层级的叶子节点  \n",
    "leaf_nodes = get_leaf_nodes_at_step(all_nodes, step)  \n",
    "  \n",
    "# 写入到文件  \n",
    "write_leaf_nodes_to_file(leaf_nodes, output_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import re  \n",
    "  \n",
    "DELIMITER = \"step\"  \n",
    "TARGET = \"the answer is\"  \n",
    "  \n",
    "def extract_answer(text):  \n",
    "    pattern = r\"answer is[:\\s]*\\(?(?P<answer>[A-J])\\)?\"  \n",
    "    match = re.search(pattern, text, re.IGNORECASE)  \n",
    "    if match:  \n",
    "        return match.group(\"answer\")  \n",
    "    else:  \n",
    "        return extract_again(text)  \n",
    "  \n",
    "def extract_again(text):  \n",
    "    pattern = r'.*[aA]nswer[:\\s]*([A-J])'  \n",
    "    match = re.search(pattern, text)  \n",
    "    if match:  \n",
    "        return match.group(1)  \n",
    "    else:  \n",
    "        return extract_final(text)  \n",
    "  \n",
    "def extract_final(text):  \n",
    "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"  \n",
    "    match = re.search(pattern, text, re.DOTALL)  \n",
    "    if match:  \n",
    "        return match.group(0)  \n",
    "    else:  \n",
    "        return None  \n",
    "  \n",
    "class Node:  \n",
    "    def __init__(self, qid, idx, x, y, step, parent=None, next_nodes=None, gt_answer=None, category=None):  \n",
    "        self.qid = qid  \n",
    "        self.idx = idx  \n",
    "        self.x = x  \n",
    "        self.y = y  \n",
    "        self.step = step  \n",
    "        self.parent = parent  \n",
    "        self.next_nodes = next_nodes if next_nodes is not None else []   \n",
    "        self.gt_answer = gt_answer  \n",
    "        self.pred_acc = self.get_acc()  \n",
    "        self.is_leaf = False  \n",
    "        self.is_right = False  \n",
    "        self.label_he = 0  \n",
    "        self.label_se = 0  \n",
    "        self.he_list = []  \n",
    "        self.se_list = []  \n",
    "        self.category = category  \n",
    "  \n",
    "    def get_info(self):  \n",
    "        return {  \n",
    "            'qid': self.qid,  \n",
    "            'idx': self.idx,  \n",
    "            'x': self.x,  \n",
    "            'y': self.y,  \n",
    "            'step': self.step,  \n",
    "            'parent': self.parent,  \n",
    "            'next_nodes': self.next_nodes,  \n",
    "            'pred_acc': self.pred_acc,  \n",
    "            \"label_he\": self.label_he,  \n",
    "            \"label_se\": self.label_se,  \n",
    "            \"gt_answer\": self.gt_answer,  \n",
    "            \"pred_acc\": self.pred_acc,  \n",
    "            \"pred\": self.pred,  \n",
    "            \"he_list\": self.he_list,  \n",
    "            \"se_list\": self.se_list,  \n",
    "            \"category\": self.category  \n",
    "        }  \n",
    "  \n",
    "    def get_acc(self):  \n",
    "        pred = extract_answer(self.y)  \n",
    "        self.pred = pred  \n",
    "        return pred == self.gt_answer  \n",
    "  \n",
    "    def get_is_leaf(self):  \n",
    "        return False  \n",
    "  \n",
    "    def get_is_right(self, delimiter=DELIMITER):  \n",
    "        step_pattern = re.compile(re.escape(delimiter), re.IGNORECASE)  \n",
    "        matches = list(step_pattern.finditer(self.y))  \n",
    "        return len(matches) == self.step and self.step > 0  \n",
    "  \n",
    "def process_line(line, step):  \n",
    "    data = json.loads(line)  \n",
    "    qid = list(data.keys())[0]  \n",
    "    nodes_data = data[qid]  \n",
    "    all_nodes = []  \n",
    "    for node_info in nodes_data:  \n",
    "        node = Node(  \n",
    "            qid=node_info['qid'],  \n",
    "            idx=node_info['idx'],  \n",
    "            x=node_info['x'],  \n",
    "            y=node_info['y'],  \n",
    "            step=node_info['step'],  \n",
    "            parent=node_info['parent'],  \n",
    "            next_nodes=node_info['next_nodes'],  \n",
    "            gt_answer=node_info['gt_answer'],  \n",
    "            category=node_info['category']  \n",
    "        )  \n",
    "        all_nodes.append(node)  \n",
    "  \n",
    "    leaf_nodes = get_leaf_nodes_at_step(all_nodes, step)  \n",
    "    return leaf_nodes  \n",
    "  \n",
    "def get_leaf_nodes_at_step(all_nodes, step):  \n",
    "    leaf_nodes = []  \n",
    "    for node in all_nodes:  \n",
    "        if node.step == step:  \n",
    "            leaf_nodes.append(node.get_info())  \n",
    "    return leaf_nodes  \n",
    "  \n",
    "def process_file(input_file, output_file, step):  \n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:  \n",
    "        for line in infile:  \n",
    "            leaf_nodes = process_line(line, step)  \n",
    "            for leaf in leaf_nodes:  \n",
    "                outfile.write(json.dumps(leaf) + '\\n')  \n",
    "  \n",
    "# Example usage  \n",
    "input_file = 'data/prm_tree_path/Meta-Llama-3.1-8B-Instruct_0.8_Meta-Llama-3.1-8B-Instruct3_match1_greedy1_start8564_end8567.json'  \n",
    "output_file = 'data/decode_step/output.json'  \n",
    "step = 3  # The step level you want to extract  \n",
    "  \n",
    "process_file(input_file, output_file, step)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
